---
title: 5.4 游戏客户广州小迈微服务治理最佳实践
keywords: [ SCA ]
description: 背景广州小迈于2015年1月成立，是一家致力以数字化领先为优势，实现业务高质量自增长的移动互联网科技公司。始终坚持以用户价值为中心，以数据为驱动，为用户开发丰富的工具应用、休闲游戏、益智、运动等系列的移动应用。累计开发400余款产品，累计用户下载安装量破七亿。众所周知，游戏行业的主要特点：种类...
---
<a name="ru1Ta"></a>
### 背景
广州小迈于2015年1月成立，是一家致力以数字化领先为优势，实现业务高质量自增长的移动互联网科技公司。始终坚持以用户价值为中心，以数据为驱动，为用户开发丰富的工具应用、休闲游戏、益智、运动等系列的移动应用。累计开发400余款产品，累计用户下载安装量破七亿。<br />众所周知，游戏行业的主要特点：种类繁多、推广昂贵、依赖爆款、高性能&更新快、极致稳定、弹缩明显、架构简洁（比较流行烟囱式的部署）。基于这些特性，游戏企业需要一套高可用、易扩展、具备自动弹性的架构来支撑业务。我们小迈的业务架构也是随着业务发展不断演进，从单体到微服务架构，也计划往容器化方向演进。

![服务治理架构图_5-4-1 第五章第四节第一张图.png](https://intranetproxy.alipay.com/skylark/lark/0/2022/png/25045/1648110804174-47d27f70-8b73-420d-808a-dc0f321b0244.png#clientId=u8e1779ec-2b0a-4&from=drop&id=I5obG&originHeight=1667&originWidth=2668&originalType=binary&ratio=1&rotation=0&showTitle=false&size=63804&status=done&style=none&taskId=ucae91bd9-1fe5-4722-966b-7d520256981&title=)

但整个落地过程中最大的问题是：<br />1.因游戏推广涉及到买量，经常出现容量评估不准，资源利用率低。<br />2.传统服务器部署架构，不能快速自动弹缩。<br />3.缺少微服务治理，发布不稳定：无服务监控，尤其应用发版/扩缩容时流量有损，对终端游戏客户是不能接受的。发布之后，瞬间一批流量被打到新实例，导致部分请求超时/报错。

<a name="DeRQw"></a>
### 问题分析
问题1和问题2 均属于容量规划和弹性的范畴，原因均和业务侧的流量有关。<br />问题3 服务治理就稍微麻烦一点了，我们仔细分析了应用发版时流量有损的原因，本质上还是服务无法及时下线导致的。<br />![服务治理架构图_5-4-2 第五章第四节第二张图.png](https://intranetproxy.alipay.com/skylark/lark/0/2022/png/25045/1648110863294-75a5f508-9467-4772-8021-b1edbf40a679.png#clientId=u8e1779ec-2b0a-4&from=drop&id=UyRqj&originHeight=1667&originWidth=2667&originalType=binary&ratio=1&rotation=0&showTitle=false&size=60298&status=done&style=none&taskId=u6ff13c5e-b06b-4fbb-8df3-62385d9e093&title=)

图中有服务消费者A1-A2和提供者B1-B2。B1-B2 注册到注册中心，A1-A2从注册中心刷新服务列表。提供者 B 发新版本时，先对 B1操作，首先停止 Java 进程，服务停止过程又分为主动销毁和被动销毁，主动销毁是准实时的，被动销毁的时间由不同的注册中心决定，最差的情况可能需要一分钟。

如果应用正常停止，Dubbo 框架的 ShutdownHook 能正常被执行，耗时基本上可忽略不计。如果应用非正常停止，比如直接 Kill-9 或者是 Docker 镜像构建时，Java 进程不是1号进程，且没有把 Kill 信号传递给应用的话，服务提供者是不会主动去注销节点，它会等待注册中心去发现、被动地去感知服务下线的过程。从B1提供者下线到Nacos注册中心感知并通知消费者，整个耗时最差需要50秒。这段时间内消费端所有请求都可能会出现问题，所以发布时会出现各种报错。


![服务治理架构图_5-4-3 第五章第四节第三张图.png](https://intranetproxy.alipay.com/skylark/lark/0/2022/png/25045/1648110904162-df3b77a7-47a3-4256-8bf8-e19a57b3a48a.png#clientId=u8e1779ec-2b0a-4&from=drop&id=u2d1ba487&originHeight=1667&originWidth=2668&originalType=binary&ratio=1&rotation=0&showTitle=false&size=61415&status=done&style=none&taskId=u4514b841-de1a-4f8b-8d19-d3920236154&title=)


<a name="hpr4F"></a>
### 方案选型
        针对这些问题，我们当时内部讨论了几种方案，但都存在一些弊端：<br />**方案一：开源微服务定制+自建K8s**<br />在开源微服务基础上做一些定制，解决发布时流量有损和新实例流量分配等服务治理问题。比如消费端通过轮询注册中心的提供者列表来尽量避免流量有损，虽然有一定效果，但无法保证极极短有损，其他的一些高级治理能力也需挨个定制开发，比较耗费开发人力且存在稳定性风险。容量和弹性的问题考虑过自建K8s，但学习曲线太陡峭，短期内无法组建专业团队。

**方案二：开源微服务定制+ESS弹性**<br />和方案一的差异是通过ESS来做容量规划和自动弹性，虽然能缓解弹性备容问题，但弹性效率还是有点慢，且资源利用率的问题还是没有得到解决。

        后来，经过阿里云同事介绍，**很快又有了方案三** —— 使用Serverless 应用引擎（简称 SAE）+ MSE，也是最终落地的方案。我们主要看中的是：该方案提供了一整套开箱即用的微服务治理能力，比开源更丰富稳定。接入简单，war/jar直接部署，不需要学习容器知识。极致的弹性能力，想弹多少就弹多少，想什么时候弹就什么时候弹，无需人工介入。
<a name="ZTZk7"></a>
### 
<a name="in8Jp"></a>
### 落地实施
整个SAE的落地过程我们是先在新业务中试点，并且采用ECS+SAE混部逐渐切流的方式渐进式推进的。在解决业务侧核心痛点的同时，我们也完善了一些新能力。

**1.解决痛点问题 ——  应用发版时服务无法及时下线**

对我们用户侧来说，只需要在SAE 控制台启用无损下线功能，配置微服务应用Prestop脚本，即可做到白天也能无损发布，详细操作参考官方文档。我们也找阿里云同学了解到了实现原理：在应用创建部署时内置了MSE agent，绕过了注册中心，由服务提供者直接通知消费端最新的服务列表的。<br />![服务治理架构图_5-4-4 第五章第四节第四张图.png](https://intranetproxy.alipay.com/skylark/lark/0/2022/png/25045/1648110927121-417f3bd8-c68d-4562-b645-2761e23ba164.png#clientId=u8e1779ec-2b0a-4&from=drop&id=u3d2cf45e&originHeight=1667&originWidth=2667&originalType=binary&ratio=1&rotation=0&showTitle=false&size=62462&status=done&style=none&taskId=u7b137748-4dce-43c4-b930-bbafe036232&title=)<br />SAE 做了两件事情，第一，服务提供者在应用发布前，会主动向服务注册中心注销应用，并将应用标记为已下线状态，将原来停止进程阶段的注销变成了 preStop 阶段注销进程。在接收到服务消费者的请求时，首先会正常处理本次请求，并且通知服务消费者此节点已经下线，在此之后消费者收到通知后，会立即刷新自己的服务列表，在此之后服务消费者就不会再把请求发到服务提供者 B1 的实例上。

基于该方案，下线感知时间大大缩短，从原来的分钟级别做到准实时的，确保应用发布时流量无损，我们的游戏客户再也没有投诉。比开源定制方案更实时、更稳定（经过双11考验）、无需投入研发。


**2.解决痛点问题 ——  新实例上线流量有损**<br />一般情况下，新实例业务就绪需要一个过程，如果还没就绪就把它加到注册中心让消费端去访问，或者新实例一启动就承载过大流量，极易出现大量请求响应慢，资源阻塞，应用实例宕机的现象。SAE集成了MSE的无损上线能力，提供了自定义延迟到注册中心、小流量服务预热，微服务readniess探针检查的功能，很好的解决了新实例流量有损的问题。虽然Dubbo原生也有类似的解决思路，但需要开发者自研，SAE + MSE 提供的是产品化的方案、简单易用的同时还提供了可观测能力。


**3.完善微服务治理周边配套**<br />在迁移到SAE的过程中，偶尔也会碰到一些应用状态异常的问题。我们之前没有应用监控的能力，遇到此类问题非常痛苦，也计划投入人力自建APM。但发现SAE天然就集成了Arms应用监控，能够看到应用的调用关系拓扑图，可以定位到慢SQL、慢服务、方法的调用堆栈、进而定位到代码级别的问题。也能查看各种维度的  TopN  关注应用，实现1人轻松运维成千上百个应用，十分方便，极大的提升了我们的排查效率。

后续我们还会继续评估 MSE 的微服务网关产品，如果合适的话也会考虑替换我们的开源网关。

**4.SAE极致弹性**<br />SAE提供了丰富的弹性指标和策略，我们主要用的是cpu，mem、QPS、RT指标来自动弹性，发现SAE真的能在峰值时秒级自动扩容，峰谷时按需自动缩容，使用 SAE 之后比以往 ECS 长期保有方式节省了 40% 左右的硬件成本。

<a name="q2Adl"></a>
### 落地效果
通过和 SAE 平台不断的磨合验证，我们游戏团队的应用都已经全部迁移到 SAE。整个迁移过程平滑，无任何改造成本，零故障，并且只投入了 1 个研发人员。<br />![服务治理架构图_5-4-5 第五章第四节第五张图.png](https://intranetproxy.alipay.com/skylark/lark/0/2022/png/25045/1648110947996-fba82e75-eb0b-4e93-bd3c-01610420bb2a.png#clientId=u8e1779ec-2b0a-4&from=drop&id=hFXWL&originHeight=1667&originWidth=2668&originalType=binary&ratio=1&rotation=0&showTitle=false&size=87601&status=done&style=none&taskId=uc5edeb2b-a1c1-49ad-90e9-3c0841f0b4c&title=)


后续，我们也会在公司层面加大宣传 SAE+MSE 提供的微服务 on Serverless的解决方案，让整个公司都能低门槛充分享受云原生带来的技术红利。




